{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ch02_util3 (1).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VHDRKL/1031/blob/main/ch02_util3_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcI0P3J3iDRx"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential  #← 匯入 Keras 的序列式模型類別\n",
        "from tensorflow.keras.layers import Dense       #← 匯入 Keras 的密集層類別\n",
        "\n",
        "#傳回預處理好的 MNIST 資料集： (x_train, x_test), (y_train, y_test)\n",
        "def mnist_data():\n",
        "    # 載入 MNIST 資料集並預處理樣本 & 標籤資料\n",
        "    (train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "    x_train = train_images.reshape((60000, 28 * 28)) #←將 (60000,28,28) 轉換成 (60000,784)\n",
        "    x_train = x_train.astype('float32') / 255    #←再將 0~255 的像素值轉換成 0~1 的浮點數\n",
        "    x_test = test_images.reshape((10000, 28 * 28))  #}←將 10000 筆測試樣本做同樣的轉換\n",
        "    x_test = x_test.astype('float32') / 255         #}\n",
        "    y_train = to_categorical(train_labels)  #←將訓練標籤做 One-hot 編碼\n",
        "    y_test  = to_categorical(test_labels)  #←將測試標籤做 One-hot 編碼\n",
        "    return (x_train, x_test), (y_train, y_test)\n",
        "\n",
        "#傳回新建立並編譯好的 MNIST 模型\n",
        "def mnist_model():\n",
        "    model = Sequential()                 #← 建立序列模型物件\n",
        "    model.add(Dense(512, activation='relu', input_dim= 784)) #← 加入第一層\n",
        "    model.add(Dense(10, activation='softmax'))               #← 加入第二層\n",
        "    model.compile(optimizer='rmsprop',             #← 指定優化器\n",
        "      loss='categorical_crossentropy', #← 指定損失函數\n",
        "      metrics=['acc'])                 #← 指定評量準則\n",
        "    return model\n",
        "def mnist_model3():\n",
        "    model = Sequential()                 #← 建立序列模型物件\n",
        "    model.add(Dense(512, activation='relu', input_dim= 784)) #← 加入第一層\n",
        "    model.add(Dense(10, activation='softmax')) \n",
        "    sgd=tf.keras.optimizers.SGD(lr=0.01,momentum=0.9, clipvalue=0.5  )             \n",
        "    model.compile(optimizer=sgd,             #← 指定優化器\n",
        "      loss='categorical_crossentropy', #← 指定損失函數\n",
        "      metrics=['acc'])                 #← 指定評量準則\n",
        "    return model\n",
        "def mnist_model4():\n",
        "    model = Sequential()                 #← 建立序列模型物件\n",
        "    model.add(Dense(512, activation='relu', input_dim= 784)) #← 加入第一層\n",
        "    model.add(Dense(10, activation='softmax')) \n",
        "    sgd=tf.keras.optimizers.SGD(lr=0.01,momentum=0.9,decay=1e-6,nesterov=True)             \n",
        "    model.compile(optimizer=sgd,             #← 指定優化器\n",
        "      loss='categorical_crossentropy', #← 指定損失函數\n",
        "      metrics=['acc'])                 #← 指定評量準則\n",
        "    return model\n",
        "def mnist_model5():\n",
        "    model = Sequential()                 #← 建立序列模型物件\n",
        "    model.add(Dense(512, activation='relu', input_dim= 784)) #← 加入第一層\n",
        "    model.add(Dense(10, activation='softmax')) \n",
        "    rms=tf.keras.optimizers.RMSprop(lr=0.001,rho=0.9,epsilon=1e-07, \n",
        "      momentum=0.0,decay=0)             \n",
        "    model.compile(optimizer=rms,             #← 指定優化器\n",
        "      loss='categorical_crossentropy', #← 指定損失函數\n",
        "      metrics=['acc'])                 #← 指定評量準則\n",
        "    return model\n",
        "def mnist_model7():\n",
        "    model = Sequential()                 #← 建立序列模型物件\n",
        "    model.add(Dense(512, activation='relu', input_dim= 784)) #← 加入第一層\n",
        "    model.add(Dense(10, activation='softmax')) \n",
        "    adadelta=tf.keras.optimizers.Adadelta(lr=0.001,rho=0.95,epsilon=1e-07,decay=0)             \n",
        "    model.compile(optimizer=adadelta,             #← 指定優化器\n",
        "      loss='categorical_crossentropy', #← 指定損失函數\n",
        "      metrics=['acc'])                 #← 指定評量準則\n",
        "    return model\n",
        "\n",
        "def mnist_model8():\n",
        "    model = Sequential()                 #← 建立序列模型物件\n",
        "    model.add(Dense(512, activation='relu', input_dim= 784)) #← 加入第一層\n",
        "    model.add(Dense(10, activation='softmax')) \n",
        "    adam=tf.keras.optimizers.Adam(lr=0.001,beta_1=0.9,beta_2=0.999,\n",
        "         epsilon=1e-07,decay=0, amsgrad=False)             \n",
        "    model.compile(optimizer=adam,             #← 指定優化器\n",
        "      loss='categorical_crossentropy', #← 指定損失函數\n",
        "      metrics=['acc'])                 #← 指定評量準則\n",
        "    return model\n",
        "def mnist_model9():\n",
        "    model = Sequential()                 #← 建立序列模型物件\n",
        "    model.add(Dense(512, activation='relu', input_dim= 784)) #← 加入第一層\n",
        "    model.add(Dense(10, activation='softmax')) \n",
        "    adamax=tf.keras.optimizers.Adamax(lr=0.001,beta_1=0.9,beta_2=0.999,\n",
        "         epsilon=1e-07,decay=0)             \n",
        "    model.compile(optimizer=adamax,             #← 指定優化器\n",
        "      loss='categorical_crossentropy', #← 指定損失函數\n",
        "      metrics=['acc'])                 #← 指定評量準則\n",
        "    return model\n",
        "def mnist_model10():\n",
        "    model = Sequential()                 #← 建立序列模型物件\n",
        "    model.add(Dense(512, activation='relu', input_dim= 784)) #← 加入第一層\n",
        "    model.add(Dense(10, activation='softmax')) \n",
        "    nadam=tf.keras.optimizers.Nadam(lr=0.001,beta_1=0.9,beta_2=0.999,\n",
        "         epsilon=1e-07)             \n",
        "    model.compile(optimizer=nadam,             #← 指定優化器\n",
        "      loss='categorical_crossentropy', #← 指定損失函數\n",
        "      metrics=['acc'])                 #← 指定評量準則\n",
        "    return model    \n",
        "def mnist_model6():\n",
        "    model = Sequential()                 #← 建立序列模型物件\n",
        "    model.add(Dense(512, activation='relu', input_dim= 784)) #← 加入第一層\n",
        "    model.add(Dense(10, activation='softmax')) \n",
        "    adagrad=tf.keras.optimizers.Adagrad(lr=0.001,epsilon=1e-07,decay=0)             \n",
        "    model.compile(optimizer=adagrad,             #← 指定優化器\n",
        "      loss='categorical_crossentropy', #← 指定損失函數\n",
        "      metrics=['acc'])                 #← 指定評量準則\n",
        "    return model    \n",
        "def mnist_model2():\n",
        "  model=Sequential()\n",
        "  model.add(layers.Input(shape=[784]))\n",
        "  model.add(layers.Dense(512, activation='relu',name='f1'))\n",
        "  model.add(layers.Dense(256, activation='relu',name='f2'))\n",
        "  model.add(layers.Dense(128, activation='relu',name='f3'))\n",
        "  model.add(layers.Dense(64, activation='relu',name='f4'))\n",
        "  model.add(layers.Dense(32, activation='relu',name='f5'))\n",
        "  model.add(layers.Dense(16, activation='relu',name='f6'))\n",
        "  model.add(layers.Dense(10, activation='softmax',name='f7'))\n",
        "  model.compile(optimizer='rmsprop',             #← 指定優化器\n",
        "      loss='categorical_crossentropy', #← 指定損失函數\n",
        "      metrics=['acc']) \n",
        "  return model\n",
        "###################################################################\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 繪製線圖 (可將訓練時所傳回的損失值或準確率等歷史記錄繪製成線圖)\n",
        "# history: 內含一或多筆要繪資料的字典, 例如：{'loss': [4,2,1,…], 'acc': [2,3,5,…]}\n",
        "# keys: 以 tuple 或串列指定 history 中要繪製的 key 值, 例如：('loss', 'acc')\n",
        "# title: 以字串指定圖表的標題文字\n",
        "# xyLabel: 以 tuple 或串列指定 x, y 軸的說明文字, 例如：('epoch', 'Accuracy')\n",
        "# ylim: 以 tuple 或串列指定 y 軸的最小值及最大值, 例如 (1, 3), 超出範圍的值會被忽略\n",
        "# size: 以 tuple 指定圖的尺寸, 預設為 (6, 4) (即寬 6 高 4 英吋)\n",
        "def plot(history_dict, keys, title=None, xyLabel=[], ylim=(), size=()):\n",
        "    lineType = ('-', '--', '.', ':')    # 線條的樣式, 畫多條線時會依序採用\n",
        "    if len(ylim)==2: plt.ylim(*ylim)    # 設定 y 軸最小值及最大值\n",
        "    if len(size)==2: plt.gcf().set_size_inches(*size)  # size預設為 (6,4)\n",
        "    epochs = range(1, len(history_dict[keys[0]])+1)  # 計算有幾週期的資料\n",
        "    for i in range(len(keys)):   # 走訪每一個 key (例如 'loss' 或 'acc' 等)\n",
        "        plt.plot(epochs, history_dict[keys[i]], lineType[i])  # 畫出線條\n",
        "    if title:   # 是否顯示標題欄\n",
        "        plt.title(title)\n",
        "    if len(xyLabel)==2:  # 是否顯示 x, y 軸的說明文字\n",
        "        plt.xlabel(xyLabel[0])\n",
        "        plt.ylabel(xyLabel[1])\n",
        "    plt.legend(keys, loc='best') # 顯示圖例 (會以 key 為每條線的說明)\n",
        "    plt.show()  # 顯示出畫好的圖\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AburPxbLiJ4X",
        "outputId": "40dfab0f-fcc0-478b-b842-aeb9e00f3591",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "(x_train, x_test), (y_train, y_test)=mnist_data()\n",
        "model=mnist_model()\n",
        "model.fit(x_train, y_train, batch_size=32,epochs=5,validation_split=0.01)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1857/1857 [==============================] - 11s 6ms/step - loss: 0.2020 - acc: 0.9402 - val_loss: 0.1655 - val_acc: 0.9750\n",
            "Epoch 2/5\n",
            "1857/1857 [==============================] - 10s 6ms/step - loss: 0.0903 - acc: 0.9734 - val_loss: 0.1672 - val_acc: 0.9750\n",
            "Epoch 3/5\n",
            "1857/1857 [==============================] - 10s 6ms/step - loss: 0.0648 - acc: 0.9816 - val_loss: 0.1679 - val_acc: 0.9767\n",
            "Epoch 4/5\n",
            "1857/1857 [==============================] - 10s 5ms/step - loss: 0.0505 - acc: 0.9856 - val_loss: 0.1790 - val_acc: 0.9767\n",
            "Epoch 5/5\n",
            "1857/1857 [==============================] - 10s 5ms/step - loss: 0.0421 - acc: 0.9890 - val_loss: 0.1961 - val_acc: 0.9750\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fdc29052f98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCDHqIq2syQ_",
        "outputId": "15203d82-6de5-43bf-8fcc-e05d12fd88c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "(x_train, x_test), (y_train, y_test)=mnist_data()\n",
        "model=mnist_model7()\n",
        "model.fit(x_train, y_train, batch_size=32,epochs=5,validation_split=0.01)\n",
        "#4 0.9750(sgd) 5:0.9767(rmsprop)  6:0.9383(adagrad)\n",
        "#7 0.8567(adadelta) 8 0.9767(adam)   *9 0.9783(adamax)\n",
        "#10 0.9700 nadam"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1857/1857 [==============================] - 8s 4ms/step - loss: 2.2136 - acc: 0.2274 - val_loss: 2.0036 - val_acc: 0.4217\n",
            "Epoch 2/5\n",
            "1857/1857 [==============================] - 8s 4ms/step - loss: 1.8780 - acc: 0.5339 - val_loss: 1.6799 - val_acc: 0.7183\n",
            "Epoch 3/5\n",
            "1857/1857 [==============================] - 8s 4ms/step - loss: 1.6080 - acc: 0.6963 - val_loss: 1.4119 - val_acc: 0.8050\n",
            "Epoch 4/5\n",
            "1857/1857 [==============================] - 9s 5ms/step - loss: 1.3839 - acc: 0.7560 - val_loss: 1.1920 - val_acc: 0.8400\n",
            "Epoch 5/5\n",
            "1857/1857 [==============================] - 9s 5ms/step - loss: 1.2017 - acc: 0.7871 - val_loss: 1.0176 - val_acc: 0.8567\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fdc17381e10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYrbWuFlkyjF",
        "outputId": "3da92a63-87a9-4bad-bf57-69447ae82d9b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "(x_train, x_test), (y_train, y_test)=mnist_data()\n",
        "model=mnist_model3()\n",
        "model.fit(x_train, y_train, batch_size=32,epochs=5,validation_split=0.01)#0.9783"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1857/1857 [==============================] - 6s 3ms/step - loss: 0.2890 - acc: 0.9171 - val_loss: 0.1871 - val_acc: 0.9533\n",
            "Epoch 2/5\n",
            "1857/1857 [==============================] - 6s 3ms/step - loss: 0.1295 - acc: 0.9634 - val_loss: 0.1559 - val_acc: 0.9650\n",
            "Epoch 3/5\n",
            "1857/1857 [==============================] - 6s 3ms/step - loss: 0.0896 - acc: 0.9742 - val_loss: 0.1314 - val_acc: 0.9767\n",
            "Epoch 4/5\n",
            "1857/1857 [==============================] - 6s 3ms/step - loss: 0.0675 - acc: 0.9808 - val_loss: 0.1243 - val_acc: 0.9783\n",
            "Epoch 5/5\n",
            "1857/1857 [==============================] - 6s 3ms/step - loss: 0.0534 - acc: 0.9846 - val_loss: 0.1244 - val_acc: 0.9783\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fdc26143f60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCmv2HaMlvH9"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()  #上傳檔案\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kgzBIaLl7yE",
        "outputId": "c1842fa8-ef4e-407a-b5bb-cab7d717a6f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import util3 as u\n",
        "model=u.mnist_model3()\n",
        "(x_train, x_test), (y_train, y_test)=u.mnist_data()\n",
        "model.fit(x_train,y_train,epochs=5) #0.9846"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2886 - acc: 0.9169\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1308 - acc: 0.9628\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0908 - acc: 0.9744\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0688 - acc: 0.9807\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0551 - acc: 0.9843\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fdc257935f8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    }
  ]
}